{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "992d827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"makanan4.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b68465e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekomendasi makanan:\n",
      "1. alpukat segar (Distance Score: 0.0)\n",
      "2. tomat muda segar (Distance Score: 0.04009696706143839)\n",
      "3. baligo segar (Distance Score: 0.04387945652807579)\n",
      "4. labu air segar (Distance Score: 0.04562444757059858)\n",
      "5. wortel rebus (Distance Score: 0.05351870932735969)\n",
      "6. jeruk nipis segar (Distance Score: 0.05421769551528588)\n",
      "7. Cabai merah, segar (Distance Score: 0.0550044558585433)\n",
      "8. wortel kukus (Distance Score: 0.05660230833328639)\n",
      "9. semangka segar (Distance Score: 0.05747077364039577)\n",
      "10. bengkuang segar (Distance Score: 0.059636190301770586)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_data(filepath):\n",
    "    # Baca data dari CSV\n",
    "    data = pd.read_csv(filepath)\n",
    "\n",
    "    # Drop kolom yang tidak diperlukan\n",
    "    # Kolom tetap digunakan pada saat pembuatan API\n",
    "    data = data.drop(['id', 'kode', 'sumber', 'gambar', 'satuan'], axis=1)\n",
    "\n",
    "    # Ubah nilai yang asalnya ',' menjadi '.'\n",
    "    numeric_cols = ['air_gram', 'energi_kal', 'protein_gram', 'lemak_gram', 'karbohidrat_gram', 'serat_gram',\n",
    "                    'kalsium_mg', 'fosfor_mg', 'zatbesi_mg', 'natrium_mg', 'kalium_mg', 'tembaga_mg', 'vitc_mg']\n",
    "\n",
    "    data[numeric_cols] = data[numeric_cols].replace({',': '.'}, regex=True).astype(float)\n",
    "\n",
    "    return data, numeric_cols\n",
    "\n",
    "def scaling(data, numeric_cols):\n",
    "    scaler = StandardScaler()\n",
    "    data_normalized = scaler.fit_transform(data[numeric_cols])\n",
    "    return data_normalized, scaler\n",
    "\n",
    "def nn_predictor(prep_data):\n",
    "    neigh = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    neigh.fit(prep_data)\n",
    "    return neigh\n",
    "\n",
    "def build_pipeline(neigh, params):\n",
    "    transformer = FunctionTransformer(neigh.kneighbors, kw_args=params)\n",
    "    pipeline = Pipeline([('NN', transformer)])\n",
    "    return pipeline\n",
    "\n",
    "def extract_data(data, allergy_list):\n",
    "    filtered_data = data.copy()\n",
    "    if allergy_list is not None:\n",
    "        for allergy in allergy_list:\n",
    "            filtered_data = filtered_data[~filtered_data['nama_bahan'].str.contains(allergy, case=False, na=False)]\n",
    "            filtered_data = filtered_data[~filtered_data['jenis_pangan'].str.contains(allergy, case=False, na=False)]\n",
    "    return filtered_data\n",
    "\n",
    "def apply_pipeline(pipeline, food_indices, extracted_data):\n",
    "    return extracted_data.iloc[pipeline.transform(food_indices)[0]]\n",
    "\n",
    "def recommend(data, food_names, numeric_cols, allergy_list=None, params={'n_neighbors': 10, 'return_distance': True}):\n",
    "    extracted_data = extract_data(data, allergy_list)\n",
    "    data_normalized, scaler = scaling(extracted_data, numeric_cols)\n",
    "    neigh = nn_predictor(data_normalized)\n",
    "    pipeline = build_pipeline(neigh, params)\n",
    "    \n",
    "    # Cari indeks makanan yang cocok dengan nama makanan yang diberikan\n",
    "    food_indices = [data[data['nama_bahan'] == food_name].index[0] for food_name in food_names]\n",
    "    \n",
    "    distances, recommended_indices = pipeline.transform(data_normalized[food_indices])\n",
    "    recommended_foods = extracted_data.iloc[recommended_indices[0]]['nama_bahan'].tolist()\n",
    "    \n",
    "    return recommended_foods, distances[0]\n",
    "\n",
    "\n",
    "# Contoh penggunaan\n",
    "filepath = \"makanan8.csv\"\n",
    "allergy_list = ['susu']  # Ganti dengan alergi yang dimiliki user\n",
    "food_names = ['alpukat segar']  # Ganti dengan makanan yang dimiliki user\n",
    "\n",
    "data, numeric_cols = preprocess_data(filepath)\n",
    "recommendations, distances = recommend(data, food_names, numeric_cols, allergy_list)\n",
    "\n",
    "print(\"Rekomendasi makanan:\")\n",
    "for idx, (food, score) in enumerate(zip(recommendations, distances)):\n",
    "    print(f\"{idx+1}. {food} (Distance Score: {score})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a141913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekomendasi makanan:\n",
      "1. apel segar (Distance Score: 2.220446049250313e-16)\n",
      "2. buah pir / pear (Distance Score: 0.013623297389274258)\n",
      "3. apel malang segar (Distance Score: 0.02400054498041615)\n",
      "4. terung panjang kukus (Distance Score: 0.0792637987823811)\n",
      "5. mangga harumanis segar (Distance Score: 0.10840654271227768)\n",
      "6. duwet segar (Distance Score: 0.11193915313777125)\n",
      "7. manggis segar (Distance Score: 0.11286731721600163)\n",
      "8. buah naga putih segar (Distance Score: 0.11663718656015554)\n",
      "9. nanas palembang segar (Distance Score: 0.11917290374288991)\n",
      "10. terung bengkulu segar (Distance Score: 0.11929719291674545)\n",
      "11. jambu air segar (Distance Score: 0.12250635908213015)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_data(filepath):\n",
    "    # Baca data dari CSV\n",
    "    data = pd.read_csv(filepath)\n",
    "\n",
    "    # Drop kolom yang tidak diperlukan\n",
    "    data = data.drop(['id', 'kode', 'sumber', 'gambar'], axis=1)\n",
    "\n",
    "    # Ubah nilai yang asalnya ',' menjadi '.'\n",
    "    numeric_cols = ['air_gram', 'energi_kal', 'protein_gram', 'lemak_gram', 'karbohidrat_gram', 'serat_gram',\n",
    "                    'kalsium_mg', 'fosfor_mg', 'zatbesi_mg', 'natrium_mg', 'kalium_mg', 'tembaga_mg', 'vitc_mg']\n",
    "\n",
    "    data[numeric_cols] = data[numeric_cols].replace({',': '.'}, regex=True)\n",
    "\n",
    "    return data, numeric_cols\n",
    "\n",
    "def scaling(data, numeric_cols):\n",
    "    scaler = StandardScaler()\n",
    "    data_normalized = scaler.fit_transform(data[numeric_cols])\n",
    "    return data_normalized, scaler\n",
    "\n",
    "def nn_predictor(prep_data):\n",
    "    neigh = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    neigh.fit(prep_data)\n",
    "    return neigh\n",
    "\n",
    "def build_pipeline(neigh, params):\n",
    "    transformer = FunctionTransformer(neigh.kneighbors, kw_args=params)\n",
    "    pipeline = Pipeline([('NN', transformer)])\n",
    "    return pipeline\n",
    "\n",
    "def extract_data(data, allergy_list):\n",
    "    filtered_data = data.copy()\n",
    "    if allergy_list is not None:\n",
    "        for allergy in allergy_list:\n",
    "            filtered_data = filtered_data[~filtered_data['nama_bahan'].str.contains(allergy, case=False)]\n",
    "            filtered_data = filtered_data[~filtered_data['jenis_pangan'].str.contains(allergy, case=False)]\n",
    "    return filtered_data\n",
    "\n",
    "def apply_pipeline(pipeline, food_indices, extracted_data):\n",
    "    return extracted_data.iloc[pipeline.transform(food_indices)[0]]\n",
    "\n",
    "def recommend(data, food_names, numeric_cols, allergy_list=None, params={'n_neighbors': 11, 'return_distance': True}):\n",
    "    extracted_data = extract_data(data, allergy_list)\n",
    "    data_normalized, scaler = scaling(extracted_data, numeric_cols)\n",
    "    neigh = nn_predictor(data_normalized)\n",
    "    pipeline = build_pipeline(neigh, params)\n",
    "    \n",
    "    # Cari indeks makanan yang cocok dengan nama makanan yang diberikan\n",
    "    food_indices = [data[data['nama_bahan'] == food_name].index[0] for food_name in food_names]\n",
    "    \n",
    "    distances, recommended_indices = pipeline.transform(data_normalized[food_indices])\n",
    "    recommended_foods = extracted_data.iloc[recommended_indices[0]]['nama_bahan'].tolist()\n",
    "    \n",
    "    return recommended_foods, distances[0]\n",
    "\n",
    "\n",
    "# Contoh penggunaan\n",
    "filepath = \"makanan6.csv\"\n",
    "allergy_list = ['susu']  # Ganti dengan alergi yang dimiliki user\n",
    "food_names = ['apel segar']  # Ganti dengan makanan yang dimiliki user\n",
    "\n",
    "data, numeric_cols = preprocess_data(filepath)\n",
    "recommendations, distances = recommend(data, food_names, numeric_cols, allergy_list)\n",
    "\n",
    "print(\"Rekomendasi makanan:\")\n",
    "for idx, (food, score) in enumerate(zip(recommendations, distances)):\n",
    "    print(f\"{idx+1}. {food} (Distance Score: {score})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37abbea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makanan tersebut berada di indeks ke- [613]\n",
      "Rekomendasi makanan:\n",
      "1. apel segar (Similarity Score: 0.9862510103217272)\n",
      "2. buah pir / pear (Similarity Score: 0.9757989328132398)\n",
      "3. apel malang segar (Similarity Score: 0.9199825149140869)\n",
      "4. terung panjang kukus (Similarity Score: 0.8904701611419836)\n",
      "5. mangga harumanis segar (Similarity Score: 0.8872752353477718)\n",
      "6. duwet segar (Similarity Score: 0.8859794515311835)\n",
      "7. manggis segar (Similarity Score: 0.8821784400315614)\n",
      "8. buah naga putih segar (Similarity Score: 0.8796076647008712)\n",
      "9. nanas palembang segar (Similarity Score: 0.8794966664084582)\n",
      "10. terung bengkulu segar (Similarity Score: 0.8762427434845895)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Baca data dari CSV\n",
    "data = pd.read_csv(\"makanan8.csv\")\n",
    "\n",
    "# Drop kolom yang tidak diperlukan\n",
    "data = data.drop(['id', 'kode', 'sumber', 'gambar', 'satuan'], axis=1)\n",
    "\n",
    "# Ubah nilai yang asalnya ',' menjadi '.'\n",
    "numeric_cols = ['air_gram', 'energi_kal', 'protein_gram', 'lemak_gram', 'karbohidrat_gram', 'serat_gram',\n",
    "                'kalsium_mg', 'fosfor_mg', 'zatbesi_mg', 'natrium_mg', 'kalium_mg', 'tembaga_mg', 'vitc_mg']\n",
    "\n",
    "data[numeric_cols] = data[numeric_cols].replace({',': '.'}, regex=True)\n",
    "\n",
    "# Normalisasi data\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "# Hitung similarity matrix (Cosine Similarity)\n",
    "cosine_sim = cosine_similarity(data_normalized, data_normalized)\n",
    "\n",
    "\n",
    "# Fungsi untuk mendapatkan rekomendasi makanan\n",
    "def get_recommendations(food_names, allergy_list):\n",
    "    # Cari indeks makanan yang cocok dengan nama makanan yang diberikan\n",
    "    food_indices = [data[data['nama_bahan'] == food_name].index[0] for food_name in food_names]\n",
    "    \n",
    "    print(\"Makanan tersebut berada di indeks ke-\", food_indices)\n",
    "    \n",
    "    # Filter makanan berdasarkan alergi\n",
    "    filtered_data = data.copy()\n",
    "    for allergy in allergy_list:\n",
    "        filtered_data = filtered_data[~filtered_data['nama_bahan'].str.contains(allergy, case=False)]\n",
    "        filtered_data = filtered_data[~filtered_data['jenis_pangan'].str.contains(allergy, case=False)]\n",
    "    \n",
    "    # Hitung similarity antara makanan yang dimiliki user dengan makanan yang tersedia\n",
    "    sim_scores = []\n",
    "    for food_index in food_indices:\n",
    "        sim_scores.extend(list(enumerate(cosine_sim[food_index])))\n",
    "    \n",
    "    # Hitung rata-rata similarity score untuk setiap makanan yang tersedia\n",
    "    sim_scores_df = pd.DataFrame(sim_scores, columns=['index', 'score'])\n",
    "    avg_sim_scores = sim_scores_df.groupby('index')['score'].mean().reset_index()\n",
    "    \n",
    "    # Urutkan makanan berdasarkan similarity score\n",
    "    avg_sim_scores = avg_sim_scores.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    \n",
    "    # Ambil 10 makanan dengan similarity score tertinggi (kecuali makanan yang dimiliki user)\n",
    "    top_similar_food_indices = avg_sim_scores['index'].iloc[0:11].tolist()  # [1:11] karena urutan 0 adalah makanan itu sendiri\n",
    "    top_similar_food_names = data['nama_bahan'].iloc[top_similar_food_indices].tolist()\n",
    "    top_similar_food_scores = avg_sim_scores['score'].iloc[1:11].tolist()  # Nilai similarity\n",
    "    \n",
    "    return top_similar_food_names, top_similar_food_scores\n",
    "\n",
    "# Contoh penggunaan\n",
    "allergy_list = ['susu']  # Ganti dengan alergi yang dimiliki user\n",
    "food_names = ['apel segar']  # Ganti dengan makanan yang dimiliki user\n",
    "recommendations, similarity_scores = get_recommendations(food_names, allergy_list)\n",
    "print(\"Rekomendasi makanan:\")\n",
    "for idx, (food, score) in enumerate(zip(recommendations, similarity_scores)):\n",
    "    print(f\"{idx+1}. {food} (Similarity Score: {score})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324f0808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07000000000000003\n",
      "MAE: 0.22000000000000003\n",
      "RMSE: 0.26457513110645914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Misalnya kita memiliki data sebenarnya dan prediksi untuk ilustrasi\n",
    "actual_scores = [4, 3, 5, 2, 1]  # Contoh nilai sebenarnya dari user\n",
    "predicted_scores = [3.5, 2.8, 4.9, 2.2, 1.1]  # Contoh nilai prediksi dari model\n",
    "\n",
    "# Menghitung MSE, MAE, dan RMSE\n",
    "mse = mean_squared_error(actual_scores, predicted_scores)\n",
    "mae = mean_absolute_error(actual_scores, predicted_scores)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
